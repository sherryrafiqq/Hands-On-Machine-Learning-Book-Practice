{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2497ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "housing = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f520ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edde24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3192c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b677eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def split_train_test(data, test_ratio):\n",
    "#     shuffled_indices = np.random.permutation(len(data))\n",
    "    \n",
    "#     test_set_size = int(len(data) * test_ratio)\n",
    "#     test_indices = shuffled_indices[:test_set_size]\n",
    "#     train_indices = shuffled_indices[test_set_size:]\n",
    "#     return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def test_set_check(identifier, test_ratio, hash):\n",
    " return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
    " ## np.int64(identifier) --> first we standardize the identifier format into 64-bit representation. Because Python‚Äôs int type can behave slightly differently across versions and systems.\n",
    " ## then we pass it to the hash function through hash, the output is a hexadecimal string, for example: 202cb962ac59075b964b07152d234b70\n",
    " ## digest sections it into bytes by transforming it into raw binary form: \\x2c\\xb9b\\xacY\\x07[\\x96K\\x07\\x15-#Kp\n",
    " ## [-1] takes the last byte\n",
    " ## < 256* test_ratio returns true if it's less than 51\n",
    "def split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    # This is a default argument, if the user doesn't define a hash function, use hashlib.md5 by default\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n",
    "    ## It‚Äôs just a name for the variable. The underscore is used to avoid conflict with Python‚Äôs built-in function id().\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "    ## ~ in Python means not. loc selects rows based on booleans. the first part of the \n",
    "    ## return statement, are records that are 'False' or 'not in test set, or in other words the training set\n",
    "    ## the other part is the data that is 'True' or is in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25073bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_with_id = housing.reset_index() # adds an `index` column\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = housing[\"median_income\"].mean()\n",
    "median = housing[\"median_income\"].median()\n",
    "mode = housing[\"median_income\"].mode()[0]  # if multimodal, this gets the first\n",
    "iqr = housing[\"median_income\"].quantile(0.75) - housing[\"median_income\"].quantile(0.25)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode)\n",
    "print(\"IQR (middle 50% range):\", iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd15d6d",
   "metadata": {},
   "source": [
    "# üß† Income Distribution Summary\n",
    "\n",
    "## üìå Measures of Central Tendency\n",
    "\n",
    "- **Mean = 3.87** ‚Üí The average income  \n",
    "  > ŸÑŸà ÿ¨ŸÖÿπŸÜÿß ÿßŸÑŸÅŸÑŸàÿ≥ ÿØŸä ŸÉŸÑŸáÿß ŸàŸÇÿ≥ŸÖŸÜÿßŸáÿß ÿπŸÑŸâ ÿßŸÑÿπÿßÿ¶ŸÑÿßÿ™ ÿ®ÿßŸÑÿ™ÿ≥ÿßŸàŸäÿå ŸÉŸÑ ÿπŸäŸÑÿ© Ÿáÿ™ÿßÿÆÿØ ÿßŸÑŸÖÿ®ŸÑÿ∫ ÿØŸá  \n",
    "\n",
    "- **Median = 3.53** ‚Üí Half the data is below, half is above  \n",
    "  > ÿØÿ© ÿ®ŸäŸÇÿ≥ŸÖ ÿßŸÑÿØÿßÿ™ÿß ÿ®ÿßŸÑŸÜÿµÿå ŸÜÿµ ÿßŸÑÿØÿßÿ™ÿß ÿπŸÑŸâ ŸäŸÖŸäŸÜŸá ŸàÿßŸÑŸÜÿµ ÿßŸÑÿ™ÿßŸÜŸä ÿπŸÑŸâ ÿ¥ŸÖÿßŸÑŸá  \n",
    "\n",
    "- **Mode = 3.13** ‚Üí Most common value  \n",
    "  > ÿ£ÿ∑ŸàŸÑ ÿπŸÖŸàÿØ ŸÅŸä ÿßŸÑŸÄ histogram  \n",
    "  > ŸÑŸà ÿßŸÑÿØÿßÿ™ÿß ÿØŸä symmetric, ÿßŸÑmean, mode, median ŸáŸäŸÉŸàŸÜŸàÿß ÿπŸÑŸâ ŸÜŸÅÿ≥ ÿßŸÑÿÆÿ∑\n",
    "\n",
    "---\n",
    "\n",
    "## üìä IQR (Interquartile Range)\n",
    "\n",
    "- **IQR = Q3 - Q1 = 4.75 - 2.57 = 2.18**\n",
    "- Represents the middle 50% of the data (where \"most values live\")\n",
    "- If you shade the region from **2.57 to 4.75**, that‚Äôs the IQR band  \n",
    "  > ÿßŸÑÿ≠ÿ®ÿ© ÿßŸÑŸÑŸä ŸÅŸäŸáŸÖ ÿ£ÿ∑ŸàŸÑ ÿπŸàÿßŸÖŸäÿØ ŸÅŸä ÿßŸÑÿØÿßÿ™ÿß\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Visual Insight\n",
    "\n",
    "- The **mode** at ~3.13 suggests the **peak of the histogram** is near 3.\n",
    "- The **mean > median > mode** implies the distribution is **right-skewed**, probably due to a few people with very high incomes.\n",
    "\n",
    "> This matches the author's eyeball estimate of **2‚Äì5** as the range where most values are concentrated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(housing[\"median_income\"], bins=50, edgecolor='black')\n",
    "plt.axvline(mean, color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(median, color='blue', linestyle='-', label='Median')\n",
    "plt.axvline(mode, color='green', linestyle='-.', label='Mode')\n",
    "plt.axvspan(\n",
    "    housing[\"median_income\"].quantile(0.25),\n",
    "    housing[\"median_income\"].quantile(0.75),\n",
    "    color='yellow', alpha=0.3, label='IQR Range (Q1‚ÄìQ3)'\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of Median Income\")\n",
    "plt.xlabel(\"Median Income\")\n",
    "plt.ylabel(\"Number of Houses\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd3078",
   "metadata": {},
   "source": [
    "# üìê What is Skewness?\n",
    "\n",
    "**Skewness** measures the **asymmetry** of a distribution.\n",
    "\n",
    "- **Symmetric** ‚Üí Left side ‚âà Right side  \n",
    "- **Positive (Right) Skewed** ‚Üí Long tail on the right  \n",
    "- **Negative (Left) Skewed** ‚Üí Long tail on the left  \n",
    "\n",
    "---\n",
    "\n",
    "## üß† Rule of Thumb: Order of Mean, Median, Mode\n",
    "\n",
    "| Skewness Type     | Order (from lowest to highest)     | Shape Insight                   |\n",
    "|-------------------|-------------------------------------|----------------------------------|\n",
    "| **Left Skew (‚àí)** | Mean < Median < Mode               | Long tail on the **left**       |\n",
    "| **Symmetric (0)** | Mean ‚âà Median ‚âà Mode               | Bell-shaped (like normal dist.) |\n",
    "| **Right Skew (+)**| Mode < Median < Mean               | Long tail on the **right**      |\n",
    "\n",
    "---\n",
    "\n",
    "üîÅ **Tip**: Think of the **mean** as the value that's most sensitive to outliers.\n",
    "\n",
    "- In a **right-skewed** distribution (e.g., incomes), **extreme high values** will **pull the mean upward**.\n",
    "- In a **left-skewed** distribution (e.g., test scores with penalties), **extreme low values** will **pull the mean downward**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"median_income\"].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0bb23",
   "metadata": {},
   "source": [
    "# Interpretation:\n",
    "\n",
    "> 0 ‚Üí Symmetric\n",
    "\n",
    "> more than 0 ‚Üí Right-skewed\n",
    "\n",
    "> less than 0 ‚Üí Left-skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92830ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) ## 1 train test pair - test percentage - shuffling strategy\n",
    "## split is an object of the StratifiedShuffleSplit class, it has a .split() method\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]): ## since you set n_splits=1, it will loop once\n",
    "    ## split.split is a generator that will output the indices of the train and test sets.\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154161b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].value_counts() / len(housing) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "housing[\"income_cat\"].value_counts().sort_index().plot(kind=\"barh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Create the income_cat column (if not already present)\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Step 2: Do random sampling (normal train_test_split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set_rand, test_set_rand = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Do stratified sampling\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "# Step 4: Compute proportions\n",
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts(normalize=True).sort_index()\n",
    "\n",
    "overall_props = income_cat_proportions(housing)\n",
    "rand_props = income_cat_proportions(test_set_rand)\n",
    "strat_props = income_cat_proportions(strat_test_set)\n",
    "\n",
    "# Step 5: Compare and calculate %error\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Overall\": overall_props,\n",
    "    \"Random\": rand_props,\n",
    "    \"Stratified\": strat_props,\n",
    "    \"Rand. %error\": 100 * (rand_props - overall_props) / overall_props,\n",
    "    \"Strat. %error\": 100 * (strat_props - overall_props) / overall_props\n",
    "})\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfcd05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set in (strat_train_set, strat_test_set):\n",
    " set.drop([\"income_cat\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing2 = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Center the map around California\n",
    "m = folium.Map(location=[37, -119], zoom_start=6)\n",
    "\n",
    "# Extract lat/lon points\n",
    "heat_data = [[row[\"latitude\"], row[\"longitude\"]] for index, row in housing2.iterrows()]\n",
    "\n",
    "HeatMap(heat_data).add_to(m)\n",
    "\n",
    "m  # if you're in Jupyter, this will display the map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.2,\n",
    "s=housing[\"population\"]/100, label=\"population\",\n",
    "c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "## raduis = s ÿ≠ÿ¨ŸÖ ÿßŸÑÿØÿßŸäÿ±ÿ© ŸáŸà  ÿπÿØÿØ ÿßŸÑŸÜÿßÿ≥\n",
    "## color = c ŸÑŸàŸÜ ÿßŸÑÿØÿßŸäÿ±ÿ© ŸáŸà ÿßŸÑÿ≥ÿπÿ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "corr_matrix = housing2.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap of Housing Features\")\n",
    "plt.show()\n",
    "\n",
    "## Notice that this measures linear correlation only, there may be other kind of correlation that goes undetected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\"housing_median_age\"]\n",
    "scatter_matrix(housing2[attributes], figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a126bc2",
   "metadata": {},
   "source": [
    "# üìä Exploratory Data Analysis: California Housing Dataset\n",
    "\n",
    "This pairplot visualization presents relationships among four key variables:\n",
    "\n",
    "- `median_house_value`\n",
    "- `median_income`\n",
    "- `total_rooms`\n",
    "- `housing_median_age`\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Key Insights\n",
    "\n",
    "### 1. üí∞ Income vs. House Value\n",
    "- There is a clear **positive correlation** between `median_income` and `median_house_value`.\n",
    "- As income increases, house value tends to increase.\n",
    "- The relationship appears nonlinear and capped around the \\$500,000 mark, possibly due to data truncation or a cap in the dataset.\n",
    "\n",
    "### 2. üè† Total Rooms vs. House Value\n",
    "- `total_rooms` has a **very weak or no clear correlation** with `median_house_value`.\n",
    "- High room counts do not necessarily equate to high house values.\n",
    "- There‚Äôs significant variance and clustering at lower values.\n",
    "\n",
    "### 3. üè° Housing Age vs. House Value\n",
    "- `housing_median_age` shows **no clear correlation** with `median_house_value`.\n",
    "- Houses of all ages have a wide spread of values.\n",
    "- Possible explanation: location and condition may matter more than age.\n",
    "\n",
    "### 4. üßÆ Income vs. Total Rooms\n",
    "- Slight positive trend: higher-income areas tend to have more rooms.\n",
    "- But again, high dispersion suggests this isn't a strong linear relationship.\n",
    "\n",
    "### 5. üï∞ Age vs. Total Rooms & Income\n",
    "- No significant patterns between `housing_median_age` and other variables.\n",
    "- Suggests that older and newer houses can exist in areas with varying income levels and room counts.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Summary\n",
    "\n",
    "- **Median income** is the strongest predictor of **house value** among these variables.\n",
    "- **Total rooms** and **housing age** show limited predictive power on their own.\n",
    "- The distribution plots indicate skewness in `total_rooms` and `median_income`, which might require normalization or transformation for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b80e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing2.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d253955",
   "metadata": {},
   "source": [
    "## üìà Why Are There Horizontal Lines in the Scatter Plot?\n",
    "\n",
    "This scatter plot shows the relationship between `median_income` and `median_house_value`.\n",
    "\n",
    "### üß† So... what do those horizontal lines mean?\n",
    "\n",
    "The horizontal lines at the top of the plot ‚Äî especially the **thick one at \\$500,000** ‚Äî indicate that:\n",
    "\n",
    "- **House values have been capped** at \\$500,000 in the dataset.\n",
    "- Multiple entries have exactly the same `median_house_value`, creating a \"pile-up\" at that price point.\n",
    "- This is why you see a *solid horizontal bar* ‚Äî many data points overlap at that capped value.\n",
    "\n",
    "### üîé Why does this matter?\n",
    "\n",
    "- This **data truncation** can distort analysis and modeling.\n",
    "- It might:\n",
    "  - Hide true relationships in higher-income areas.\n",
    "  - Mislead regression models (e.g., underestimating the value in affluent areas).\n",
    "- Consider treating this cap carefully:\n",
    "  - Add a flag for \"capped\" data.\n",
    "  - Impute or model these separately if appropriate.\n",
    "\n",
    "> üí° TL;DR: The horizontal lines = **lots of homes priced exactly at \\$500,000**, likely because it's the upper limit recorded in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_value = 500000\n",
    "capped_count = (housing2['median_house_value'] == cap_value).sum()\n",
    "print(f\"Number of capped house values at ${cap_value}: {capped_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_to_cap = housing2[housing2['median_house_value'] >= 490000]\n",
    "print(close_to_cap['median_house_value'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bdc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing2[\"rooms_per_household\"] = housing2[\"total_rooms\"]/housing2[\"households\"]\n",
    "housing2[\"bedrooms_per_room\"] = housing2[\"total_bedrooms\"]/housing2[\"total_rooms\"]\n",
    "housing2[\"population_per_household\"] = housing2[\"population\"]/housing2[\"households\"]\n",
    "\n",
    "housing2 = housing2.drop(columns={'total_rooms','total_bedrooms'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "corr_matrix = housing2.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap of Housing Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a0124",
   "metadata": {},
   "source": [
    "# Correlation Comparison After Feature Engineering\n",
    "![](plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa1e34",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bedrooms_per_room has 158 missing values\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6fecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c566e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff738a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f513a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(imputer.statistics_, index=housing_num.columns, columns=['median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ebb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3bd777",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_imputed = pd.DataFrame(X, columns=housing_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c114cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "housing_cat = housing[\"ocean_proximity\"]\n",
    "housing_cat_encoded = encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165be8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):  # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    "('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('attribs_adder', CombinedAttributesAdder()),\n",
    "('std_scaler', StandardScaler()),\n",
    "])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff23507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Define the DataFrameSelector class\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "\tdef __init__(self, attribute_names):\n",
    "\t\tself.attribute_names = attribute_names\n",
    "\tdef fit(self, X, y=None):\n",
    "\t\treturn self\n",
    "\tdef transform(self, X):\n",
    "\t\treturn X[self.attribute_names].values\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "num_pipeline = Pipeline([\n",
    "\t('selector', DataFrameSelector(num_attribs)),\n",
    "\t('imputer', SimpleImputer(strategy=\"median\")),\n",
    "\t('attribs_adder', CombinedAttributesAdder()),\n",
    "\t('std_scaler', StandardScaler()),\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "\t('selector', DataFrameSelector(cat_attribs)),\n",
    "\t('label_binarizer', LabelBinarizer()),\n",
    "])\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "\t(\"num_pipeline\", num_pipeline),\n",
    "\t(\"cat_pipeline\", cat_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e08115",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared\n",
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38bb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
